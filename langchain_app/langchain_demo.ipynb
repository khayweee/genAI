{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e852321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4bb8c",
   "metadata": {},
   "source": [
    "## Initiating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d0327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.0\n",
    "NUM_PREDICT = 256\n",
    "MODEL = \"gemma3:12b-it-qat\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=MODEL,\n",
    "    temperature=TEMPERATURE,\n",
    "    num_predict=NUM_PREDICT,\n",
    "    use_gpu=True,\n",
    "    model_provider='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6536dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd45dbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4cf437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There| are| a| few| ways| to| translate| \"|hi|!\"| into| Italian|,| depending| on| the| level| of| formality|:|\n",
      "\n",
      "|*|   |**|Ciao|!|**| -| This| is| the| most| common| and| versatile| option|.| It|'|s| informal| and| can| be| used| for| both| greeting| and| saying| goodbye|.|\n",
      "|*|   |**|Salve|!|**| -| This| is| a| more| formal| greeting|,| suitable| for| people| you| don|'|t| know| well| or| in| more| professional| settings|.|\n",
      "|*|   |**|Ciao|!|**| (|pronounced| \"|chow|\")| -| This| is| the| most| common| and| versatile| option|.| It|'|s| informal| and| can| be| used| for| both| greeting| and| saying| goodbye|.|\n",
      "\n",
      "\n",
      "\n",
      "|Which| one| you| choose| depends| on| the| context| and| your| relationship| with| the| person| you|'|re| greeting|.||"
     ]
    }
   ],
   "source": [
    "# Streaming messages\n",
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbab8d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There| are| a| few| ways| to| translate| \"|hi|!\"| into| Italian|,| depending| on| the| level| of| formality|:|\n",
      "\n",
      "|*|   |**|Ciao|!|**| -| This| is| the| most| common| and| versatile| option|.| It|'|s| informal| and| can| be| used| for| both| greeting| and| saying| goodbye|.|\n",
      "|*|   |**|Salve|!|**| -| This| is| a| more| formal| greeting|,| suitable| for| people| you| don|'|t| know| well| or| in| more| professional| settings|.|\n",
      "|*|   |**|Ciao|!|**| (|pronounced| \"|chow|\")| -| This| is| the| most| common| and| versatile| option|.| It|'|s| informal| and| can| be| used| for| both| greeting| and| saying| goodbye|.|\n",
      "\n",
      "\n",
      "\n",
      "|Which| one| you| choose| depends| on| the| context| and| your| relationship| with| the| person| you|'|re| greeting|.||done\n"
     ]
    }
   ],
   "source": [
    "# Async streaming\n",
    "async for chunk in model.astream(messages):\n",
    "    print(chunk.content, end=\"|\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18dd62",
   "metadata": {},
   "source": [
    "## Prompt Templates  \n",
    "Context is usually a combination of user and application logic. This application logic usually  \n",
    "takes the raw user input and transforms it into a list of messages ready to pass to the LLM.  \n",
    "\n",
    "Common transformations include adding a  \n",
    "    1. **system message** or   \n",
    "    2. **formatting a template with the user input**.\n",
    "\n",
    "`Prompt Templates` are a concept in LangChain designed to asist with this transformation.  \n",
    "- They take in a raw user input and return data (a prompt) that is ready to pass into a LLM\n",
    "\n",
    "\n",
    "### Usage Pattern\n",
    "- **Prompt**: `ChatPromptTemplate` -> .invoke(kwargs)\n",
    "    - e.g. kwargs ```{'language': 'italian', 'text': 'Hi!'}```\n",
    "- **Model**: `Model` -> .invoke(`Prompt`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "194168a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c09055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"Translate the following from English into {language}\"\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template), \n",
    "        (\"user\", \"{text}\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8203adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7474bd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "568894be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There| are| a| few| ways| to| translate| \"|hi|!\"| into| Italian|,| depending| on| the| level| of| formality|:|\n",
      "\n",
      "|*|   |**|Ciao|!|**| -| This| is| the| most| common| and| versatile| option|.| It|'|s| informal| and| can| be| used| for| both| greeting| and| saying| goodbye|.|\n",
      "|*|   |**|Salve|!|**| -| This| is| a| more| formal| greeting|,| suitable| for| people| you| don|'|t| know| well| or| in| more| professional| settings|.|\n",
      "|*|   |**|Ciao|!|**| (|pronounced| \"|chow|\")| -| This| is| the| most| common| and| versatile| option|.| It|'|s| informal| and| can| be| used| for| both| greeting| and| saying| goodbye|.|\n",
      "\n",
      "\n",
      "\n",
      "|Which| one| you| choose| depends| on| the| context| and| your| relationship| with| the| person| you|'|re| greeting|.||"
     ]
    }
   ],
   "source": [
    "async for chunk in model.astream(prompt):\n",
    "    print(chunk.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
